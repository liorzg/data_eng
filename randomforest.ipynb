{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf662c2-3a7b-4e7b-81b6-bbec687bf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "pq.write_table(table, 'example.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003786d-ea2a-451c-bff1-d936a2abb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export version=`python --version |awk '{print $2}' |awk -F\".\" '{print $1$2}'`\n",
    "\n",
    "echo $version\n",
    "\n",
    "if [ $version == '36' ] || [ $version == '37' ]; then\n",
    "    echo 'Starting installation...'\n",
    "    pip3 install pyspark==2.4.8 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "elif [ $version == '38' ] || [ $version == '39' ]; then\n",
    "    pip3 install pyspark==3.1.2 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "else\n",
    "    echo 'Currently only python 3.6, 3.7 , 3.8 and 3.9 are supported, in case you need a different version please open an issue at https://github.com/IBM/claimed/issues'\n",
    "    exit -1\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df50fd-8d63-424e-8036-07ef5427e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "import os\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark2pmml import PMMLBuilder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "import logging\n",
    "import shutil\n",
    "import site\n",
    "import sys\n",
    "import wget\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f228efb-3230-4627-975e-3ee69d91de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = os.environ.get('data_csv', 'data.csv')\n",
    "data_parquet = os.environ.get('data_parquet', 'data.parquet')\n",
    "master = os.environ.get('master', \"local[*]\")\n",
    "data_dir = os.environ.get('data_dir', '../../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c97b2b-f2fc-4f3b-ae1b-1e2163544a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parquet = 'trends.parquet'\n",
    "data_csv = 'trends.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc4a0c-cb35-4cef-a0ec-f0f505767419",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = False\n",
    "if os.path.exists(data_dir + data_csv):\n",
    "    skip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d1df6-cf22-4bc9-b4b7-cfb44963b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    sc = SparkContext.getOrCreate(SparkConf().setMaster(master))\n",
    "    spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e1830-8d6f-4193-950e-69f3f4248e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    df = spark.read.parquet(data_dir + data_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304dbef1-22b9-49b4-afc9-84545600498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    if os.path.exists(data_dir + data_csv):\n",
    "        shutil.rmtree(data_dir + data_csv)\n",
    "    df.coalesce(1).write.option(\"header\", \"true\").csv(data_dir + data_csv)\n",
    "    file = glob.glob(data_dir + data_csv + '/part-*')\n",
    "    shutil.move(file[0], data_dir + data_csv + '.tmp')\n",
    "    shutil.rmtree(data_dir + data_csv)\n",
    "    shutil.move(data_dir + data_csv + '.tmp', data_dir + data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d67ddc-481e-4395-9cd3-ccc94fc4c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = os.environ.get('image_shape', '400,400')\n",
    "model_zip = os.environ.get('model_zip', 'model.zip')\n",
    "data_zip = os.environ.get('data_zip', 'data.zip')\n",
    "model_folder = os.environ.get('model', 'model')\n",
    "data = os.environ.get('data', 'data')\n",
    "epochs = int(os.environ.get('epochs', 1))\n",
    "checkpoint = boolean(os.environ.get('checkpoint', False))\n",
    "checkpoint_ip = os.environ.get('checkpoint_ip')\n",
    "checkpoint_user = os.environ.get('checkpoint_user', 'minio')\n",
    "checkpoint_pass = os.environ.get('checkpoint_pass', 'minio123')\n",
    "checkpoint_bucket = os.environ.get('checkpoint_bucket', 'checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043ebec-dff1-4dab-b6de-6802fd7fa380",
   "metadata": {},
   "outputs": [],
   "source": [
    "exists = False\n",
    "\n",
    "if checkpoint:\n",
    "    client = Minio(checkpoint_ip,\n",
    "                   checkpoint_user,\n",
    "                   checkpoint_pass,\n",
    "                   secure=False)\n",
    "\n",
    "    objects = client.list_objects(checkpoint_bucket)\n",
    "    asset_name = model_zip\n",
    "    for obj in objects:\n",
    "        if asset_name == obj.object_name:\n",
    "            exists = True\n",
    "            client.fget_object(checkpoint_bucket, model_zip, model_zip)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f154a9-0cf8-4e28-a380-50665c7cebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists:\n",
    "    unzip('.', data_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae300b7e-f60a-45eb-be58-b8295864f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists:\n",
    "    folder = glob.glob(data + \"/*\")\n",
    "    num_classes = len(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443e330-2fee-4c32-8736-d24fc7a48f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists:\n",
    "    batch_size = 32\n",
    "    input_shape = 'dummy'  # make the compiler happy\n",
    "    exec('input_shape = (' + image_shape + ')')\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        'data',\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=input_shape,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        'data',\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=123,\n",
    "        image_size=input_shape,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    train_ds = train_ds.map(lambda x, y: (x, tf.one_hot(y, depth=num_classes)))\n",
    "    val_ds = val_ds.map(lambda x, y: (x, tf.one_hot(y, depth=num_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308878d-5c72-45b6-b4a2-ada2898c7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_net(model, num_classes, freeze_layers=10, full_freeze='N'):\n",
    "    x = model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "    model_final = Model(model.input, out)\n",
    "    if full_freeze != 'N':\n",
    "        for layer in model.layers[0:freeze_layers]:\n",
    "            layer.trainable = False\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32631290-2cc0-4f51-a304-e077a529a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists:\n",
    "    exec('input_shape = (' + image_shape + ',3)')\n",
    "\n",
    "    model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=input_shape, alpha=1.0, include_top=False,\n",
    "        input_tensor=None, pooling=None, classes=num_classes,\n",
    "        classifier_activation='softmax'\n",
    "    )\n",
    "    model = my_net(model, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d17110-e9f7-4c6f-90ee-aa45be4f7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists:\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b0ec2-c4f7-4efc-ab28-ea4490beaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists:\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_ds\n",
    "    )\n",
    "    model.save(model_folder)\n",
    "    zipdir(model_zip, model_folder)\n",
    "else:\n",
    "    print('Model cached, skipping training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e91c19-7579-4069-9c60-24b75c829368",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exists:\n",
    "    size = os.path.getsize(model_zip)\n",
    "    with open(model_zip, 'rb') as fh:\n",
    "        buf = BytesIO(fh.read())\n",
    "        result = client.put_object(\n",
    "            checkpoint_bucket, model_zip, buf, length=size\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
